# RLM-OpenCode Architecture

> **True RLM for AI Coding Assistants**

A Recursive Language Model implementation that transforms how AI coding assistants handle massive contexts - making 100M+ character contexts feel natural within OpenCode.

---

## The Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE CONTEXT WALL                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   Model Context Window: ~200K tokens (~800K chars)              â”‚
â”‚                                                                  â”‚
â”‚   Your Codebase:                                                 â”‚
â”‚   â”œâ”€â”€ src/               2.3M chars                             â”‚
â”‚   â”œâ”€â”€ tests/             1.1M chars                             â”‚
â”‚   â”œâ”€â”€ docs/              500K chars                             â”‚
â”‚   â”œâ”€â”€ node_modules/     45M chars  â† ğŸ’€                         â”‚
â”‚   â””â”€â”€ logs/             10M chars                               â”‚
â”‚                         â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚   Total:               ~59M chars                               â”‚
â”‚                                                                  â”‚
â”‚   59M / 800K = 73x the model's limit                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Traditional approaches fail:
- **Stuff everything** â†’ Model hallucinates, forgets, times out
- **RAG/Search** â†’ Loses context, can't aggregate across chunks
- **Summarization** â†’ Loses critical details, irreversible

---

## The RLM Solution

Based on the paper [Recursive Language Models (arXiv:2512.24601)](https://arxiv.org/abs/2512.24601)

### Core Insight

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TRADITIONAL vs RLM APPROACH                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   TRADITIONAL:                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚  User   â”‚ â”€â”€â”€â–¶ â”‚ Context (60M chars) + Prompt   â”‚ â”€â”€â”€â–¶ ğŸ’€  â”‚
â”‚   â”‚ Prompt  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚                                                                  â”‚
â”‚   RLM:                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  User   â”‚ â”€â”€â”€â–¶ â”‚ Metadata â”‚ â”€â”€â”€â–¶ â”‚ Model sees ONLY     â”‚    â”‚
â”‚   â”‚ Prompt  â”‚      â”‚ (1KB)    â”‚      â”‚ - "Context: 60M"    â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ - Tools to access   â”‚    â”‚
â”‚                                      â”‚ - Your question     â”‚    â”‚
â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                             â”‚                    â”‚
â”‚                                             â–¼                    â”‚
â”‚                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                                      â”‚ Model calls â”‚            â”‚
â”‚                                      â”‚ TOOLS to    â”‚            â”‚
â”‚                                      â”‚ peek/search â”‚            â”‚
â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RLM REQUEST FLOW                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. REQUEST                                                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ User: "Find all API endpoints in my codebase"    â”‚        â”‚
â”‚     â”‚ Context: 60M characters (stored externally)       â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  2. MODEL RECEIVES (not the full context!)                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ System: You have access to 60M chars of context  â”‚        â”‚
â”‚     â”‚ Tools: rlm_get_context(), rlm_search()            â”‚        â”‚
â”‚     â”‚ User: Find all API endpoints...                   â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  3. MODEL WRITES CODE (or calls tools)                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ rlm_search("@app\.(get|post|put|delete)")        â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  4. SERVER EXECUTES                                              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ Searching 60M chars... Found 47 matches!         â”‚        â”‚
â”‚     â”‚ Returning: ["/api/users", "/api/posts", ...]     â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  5. MODEL RESPONDS                                               â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ "I found 47 API endpoints in your codebase..."   â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RLM-OpenCode SYSTEM                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚             â”‚                         â”‚                         â”‚   â”‚
â”‚  â”‚  OpenCode   â”‚ â—€â”€â”€â”€â”€â”€â”€â”€ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚    RLM-OpenCode         â”‚   â”‚
â”‚  â”‚  (Client)   â”‚      localhost:8768     â”‚    Server               â”‚   â”‚
â”‚  â”‚             â”‚                         â”‚                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚        â”‚                                             â”‚                  â”‚
â”‚        â”‚                                             â”‚                  â”‚
â”‚        â–¼                                             â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚             â”‚                         â”‚                         â”‚   â”‚
â”‚  â”‚   Model     â”‚ â—€â”€â”€â”€â”€â”€â”€â”€ Tools â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚    Context Store        â”‚   â”‚
â”‚  â”‚  (GLM-5)    â”‚   rlm_get_context()     â”‚    (Session Files)      â”‚   â”‚
â”‚  â”‚             â”‚   rlm_search()          â”‚    Up to 100M+ chars    â”‚   â”‚
â”‚  â”‚             â”‚   rlm_find()            â”‚                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

```
rlm-opencode/
â”œâ”€â”€ src/rlm_opencode/
â”‚   â”œâ”€â”€ __init__.py           # Package init
â”‚   â”œâ”€â”€ server.py             # FastAPI server (proxy mode)
â”‚   â”œâ”€â”€ native_server.py      # Direct API server (main)
â”‚   â”œâ”€â”€ cli.py                # CLI commands
â”‚   â”œâ”€â”€ setup.py              # Install/uninstall to opencode
â”‚   â”œâ”€â”€ session.py            # Context storage management
â”‚   â”œâ”€â”€ detector.py           # OpenCode session detection
â”‚   â”œâ”€â”€ context_tools.py      # â† NEW: RLM context tools
â”‚   â””â”€â”€ providers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py           # Provider interface
â”‚       â”œâ”€â”€ openai_compatible.py  # OpenAI-compatible streaming
â”‚       â””â”€â”€ registry.py       # Model discovery
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ ARCHITECTURE.md           # This file
â””â”€â”€ paper.pdf                 # RLM paper (add manually)
```

---

## Context Tools (The RLM Magic)

### Tool Definitions

```json
{
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "rlm_get_context",
        "description": "Get accumulated session context",
        "parameters": {
          "type": "object",
          "properties": {
            "offset": {"type": "integer", "default": 0},
            "length": {"type": "integer", "default": 10000}
          }
        }
      }
    },
    {
      "type": "function", 
      "function": {
        "name": "rlm_search",
        "description": "Search context with regex pattern",
        "parameters": {
          "type": "object",
          "properties": {
            "pattern": {"type": "string"},
            "max_results": {"type": "integer", "default": 50}
          },
          "required": ["pattern"]
        }
      }
    },
    {
      "type": "function",
      "function": {
        "name": "rlm_find",
        "description": "Find exact text occurrences",
        "parameters": {
          "type": "object",
          "properties": {
            "text": {"type": "string"},
            "max_results": {"type": "integer", "default": 100}
          },
          "required": ["text"]
        }
      }
    },
    {
      "type": "function",
      "function": {
        "name": "rlm_stats",
        "description": "Get context statistics",
        "parameters": {"type": "object", "properties": {}}
      }
    }
  ]
}
```

### Tool Behavior

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TOOL EXECUTION FLOW                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Model calls: rlm_search("def\\s+\\w+\\(.*\\):")                â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ RLM-OpenCode Server                                    â”‚     â”‚
â”‚  â”‚                                                        â”‚     â”‚
â”‚  â”‚  1. Identify session (by directory)                   â”‚     â”‚
â”‚  â”‚  2. Load context (up to 100M+ chars)                  â”‚     â”‚
â”‚  â”‚  3. Execute regex search                               â”‚     â”‚
â”‚  â”‚  4. Return results                                     â”‚     â”‚
â”‚  â”‚                                                        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  Tool Result:                                                    â”‚
â”‚  {                                                               â”‚
â”‚    "matches": [                                                  â”‚
â”‚      {"line": 45, "text": "def process_data(input):"},         â”‚
â”‚      {"line": 128, "text": "def validate_user(user):"},        â”‚
â”‚      ...                                                         â”‚
â”‚    ],                                                            â”‚
â”‚    "total": 47,                                                  â”‚
â”‚    "truncated": false                                            â”‚
â”‚  }                                                               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Comparison: rlm-server vs rlm-opencode

| Feature | rlm-server (Port 8765) | rlm-opencode (Port 8768) |
|---------|------------------------|--------------------------|
| **Context Access** | Code execution (Python) | Tool calls |
| **Model Sees** | Metadata + code template | Metadata + tool definitions |
| **Integration** | Single-shot API calls | Full OpenCode integration |
| **Tools** | `load_context()`, `llm_query()` | `rlm_get_context()`, `rlm_search()` |
| **Recursion** | `llm_query()` for sub-calls | Via OpenCode tool loop |
| **Permissions** | Sandbox (no issues) | Handled by outer OpenCode |
| **Natural Feel** | Script-like | Conversational |
| **Best For** | Batch processing | Agentic workflows |

---

## Session Management

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SESSION LIFECYCLE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ~/.local/share/rlm-opencode/                                   â”‚
â”‚  â”œâ”€â”€ sessions/                                                   â”‚
â”‚  â”‚   â”œâ”€â”€ sess_abc123_context.txt    # Accumulated context       â”‚
â”‚  â”‚   â”œâ”€â”€ sess_abc123.json           # Session metadata          â”‚
â”‚  â”‚   â””â”€â”€ ...                                                     â”‚
â”‚  â””â”€â”€ mappings/                                                   â”‚
â”‚      â””â”€â”€ directory_to_rlm.json      # Path â†’ Session mapping    â”‚
â”‚                                                                  â”‚
â”‚  Session Mapping:                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Directory              â”‚ Session ID      â”‚                   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚  â”‚ /home/user/project-a   â”‚ sess_abc123     â”‚                   â”‚
â”‚  â”‚ /home/user/project-b   â”‚ sess_def456     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                  â”‚
â”‚  Context Accumulation:                                           â”‚
â”‚  - Tool results (file reads, grep output, etc.)                 â”‚
â”‚  - Large outputs are stored, not in message history              â”‚
â”‚  - Persists across multiple OpenCode calls                       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Usage

### Setup

```bash
# Install
pip install -e .

# Add to OpenCode
rlm-opencode-setup install

# Verify
opencode models | grep rlm-opencode
```

### In OpenCode

```bash
# Use RLM-OpenCode model
opencode -m rlm-opencode/rlm-internal.rlm-core-v1

# The model now has access to tools:
# - rlm_get_context(offset, length)
# - rlm_search(pattern, max_results)  
# - rlm_find(text, max_results)
# - rlm_stats()
```

### Example Interaction

```
User: What API patterns are used in my codebase?

Model: Let me search your accumulated context...
       [calls rlm_search("@(get|post|put|delete)\\(")]

Model: I found 47 API endpoints using these patterns:
       - Flask-style: @app.get(), @app.post()
       - FastAPI-style: @router.get(), @router.post()
       ...
```

---

## Performance

### Benchmarked Results (NIAH - Needle in a Haystack)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTEXT SCALING                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Context Size     rlm-server    rlm-opencode    Vanilla        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚  1M chars         âœ“ 41s         âœ“ ~30s          âœ“ 15s          â”‚
â”‚  10M chars        âœ“ 52s         âœ“ ~60s          âœ— TIMEOUT      â”‚
â”‚  40M chars        âœ“ 109s        âœ“ ~120s         âœ— FAIL         â”‚
â”‚  100M chars       âœ“ 65s         ğŸ”„ (goal)       âœ— IMPOSSIBLE   â”‚
â”‚                                                                  â”‚
â”‚  Key: âœ“ = Success, âœ— = Failure, ğŸ”„ = In Progress                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Goals

### Phase 1: Foundation âœ…
- [x] Basic server with OpenAI-compatible API
- [x] Direct provider API calls
- [x] Session management
- [x] Context accumulation
- [x] Streaming responses

### Phase 2: True RLM (Current)
- [ ] Context tools: `rlm_get_context()`, `rlm_search()`
- [ ] Tool-based context access (no injection)
- [ ] Metadata-only prompts
- [ ] 100M+ char support

### Phase 3: Optimization
- [ ] Chunked context loading
- [ ] Lazy context retrieval
- [ ] Parallel tool execution
- [ ] Context compression hints

### Phase 4: Advanced
- [ ] Recursive sub-calls via tools
- [ ] Multi-session context sharing
- [ ] Context versioning
- [ ] Collaborative sessions

---

## Contributing

This project implements the RLM paper's Algorithm 1 with adaptations for AI coding assistants.

Key files to understand:
- `native_server.py` - Main server logic
- `context_tools.py` - Tool definitions and execution
- `session.py` - Context storage and retrieval

---

## References

- [Recursive Language Models Paper](https://arxiv.org/abs/2512.24601)
- [OpenCode](https://github.com/opencode-ai/opencode)
- [RLM Paper GitHub](https://github.com/alexzhang13/rlm)
